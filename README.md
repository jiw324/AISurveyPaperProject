# Transformer-Based Detection of Prompt Injection Attacks

Research project investigating transformer models for detecting prompt injection attacks on Large Language Models, using realistic/paraphrased hard data and multiclass evaluation to avoid inflated (100%) results.

## ğŸš€ One-Line Reproduction (after data is generated)

```bash
python run_experiment.py --fix multiclass --epochs 3 --fraction 0.25
```

**Time (recent run):** ~4â€“5 minutes on GPU (25% data, 3 epochs)  
**Result (hard data, multiclass):** 83.36% accuracy / 66.57% macro-F1

---

## ğŸ“‹ Requirements

- Python 3.11+
- See `requirements.txt` for all dependencies

---

## ğŸ“¦ Installation & Data

### 1) Install dependencies
```bash
pip install -r requirements.txt
```

### 2) Generate harder, realistic data
```bash
# Base realistic data (context-rich)
python scripts/generate_realistic_data.py

# Paraphrased/perturbed hard data
python scripts/generate_paraphrased_data.py

# Convert to multiclass (legit + 5 attack types)
python fix_100_percent_option3_multiclass.py
```

This produces:
- `data/train_multiclass.jsonl`, `data/val_multiclass.jsonl`, `data/test_multiclass.jsonl`

### 3) Run experiment (multiclass, hard data)
```bash
python run_experiment.py --fix multiclass --epochs 3 --fraction 0.25
```

---

## ğŸ“Š Output

Results saved to `results/{model_fix}/results.json` (e.g., `results/distilbert-base-uncased_multiclass/results.json`):

```json
{
  "fix": "multiclass",
  "model": "distilbert-base-uncased",
  "num_labels": 6,
  "data_fraction": 0.25,
  "epochs": 3,
  "training_time_min": 4.34,
  "test_metrics": {
    "accuracy": 0.8336,
    "precision": 0.6671,
    "recall": 0.6679,
    "f1": 0.6657
  }
}
```

---

## âš™ï¸ Customization

```bash
# Use different model
python run_experiment.py --model roberta-base

# More data
python run_experiment.py --fraction 1.0 --epochs 5

# Faster training
python run_experiment.py --fraction 0.1 --epochs 1 --batch-size 16
```

---

## ğŸ“ Project Structure

```
AISurveyPaperProject/
â”œâ”€â”€ run_experiment.py          # Main experiment file
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ config.yaml                # (optional) configuration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                  # Dataset loading
â”‚   â”œâ”€â”€ models/                # Transformer classifiers
â”‚   â””â”€â”€ training/              # Training loop & metrics
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py               # Original synthetic generator
â”‚   â”œâ”€â”€ generate_realistic_data.py     # Context-rich generator
â”‚   â””â”€â”€ generate_paraphrased_data.py   # Paraphrased/perturbed hard data
â”‚
â”œâ”€â”€ fix_100_percent_option3_multiclass.py  # Converts to 6-way multiclass
â”œâ”€â”€ use_realistic_data.py                  # Helper for realistic/hard pipeline
â”‚
â””â”€â”€ paper/
    â”œâ”€â”€ main.tex               # LaTeX paper
    â””â”€â”€ references.bib         # Bibliography
```

---

## ğŸ”¬ Research Questions

1. Can transformers detect prompt injections effectively?
2. Which attack types are hardest (multiclass view)?
3. How to avoid inflated results from easy synthetic data?
4. What components are critical (ablation plan in paper)?

See `paper/main.tex` for the complete research paper.

---

## ğŸ“š Citation

```bibtex
@misc{prompt-injection-detection-2025,
  author = {Jinghao Wang},
  title = {Transformer-Based Detection of Prompt Injection Attacks},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/jiw324/prompt-injection-detection}
}
```

---

## âœ… Requirements Compliance

- âœ… Python 3.11+
- âœ… PyTorch
- âœ… One-line reproduction (`run_experiment.py --fix multiclass ...`)
- âœ… requirements.txt
- âœ… Ablation plan in paper (encoder freeze vs full FT; follow-ups outlined)
- âœ… Complete LaTeX paper

---

**Last Updated:** December 2025

